{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cf4f5c",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "BRAUX Owen and CAMBIER Elliot\n",
    "\n",
    "    This notebook combines on-chain transaction data with market price data to create features for a prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40ecab",
   "metadata": {},
   "source": [
    "## Set up spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93061489",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928f88c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/14 12:32:40 WARN Utils: Your hostname, OBPC, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/11/14 12:32:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/14 12:32:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BDA - Feature Engineering\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc385a",
   "metadata": {},
   "source": [
    "## Load Prepared Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b09851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: double (nullable = true)\n",
      "\n",
      "\n",
      " Cleaned Price Data Schema and Sample :\n",
      "root\n",
      " |-- unix_timestamp: double (nullable = true)\n",
      " |-- price_open: double (nullable = true)\n",
      " |-- price_high: double (nullable = true)\n",
      " |-- price_low: double (nullable = true)\n",
      " |-- price_close: double (nullable = true)\n",
      " |-- volume_btc: double (nullable = true)\n",
      " |-- timestamp_utc: timestamp (nullable = true)\n",
      "\n",
      "+-------------------+----------+-----------+----------+\n",
      "|      timestamp_utc|price_open|price_close|volume_btc|\n",
      "+-------------------+----------+-----------+----------+\n",
      "|2012-01-01 11:01:00|      4.58|       4.58|       0.0|\n",
      "|2012-01-01 11:02:00|      4.58|       4.58|       0.0|\n",
      "|2012-01-01 11:03:00|      4.58|       4.58|       0.0|\n",
      "|2012-01-01 11:04:00|      4.58|       4.58|       0.0|\n",
      "|2012-01-01 11:05:00|      4.58|       4.58|       0.0|\n",
      "+-------------------+----------+-----------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Load the market price data of notebook 1\n",
    "price_data_path = \"../data/prices/btcusd_1-min_data.csv\"\n",
    "df_prices_raw = spark.read.csv(price_data_path, header=True, inferSchema=True)\n",
    "df_prices_raw.printSchema()\n",
    "\n",
    "# Clean up the price data columns\n",
    "df_prices = df_prices_raw.withColumnRenamed(\"Timestamp\", \"unix_timestamp\") \\\n",
    "                         .withColumnRenamed(\"Open\", \"price_open\") \\\n",
    "                         .withColumnRenamed(\"High\", \"price_high\") \\\n",
    "                         .withColumnRenamed(\"Low\", \"price_low\") \\\n",
    "                         .withColumnRenamed(\"Close\", \"price_close\") \\\n",
    "                         .withColumnRenamed(\"Volume\", \"volume_btc\")\n",
    "\n",
    "if \"Volume_(Currency)\" in df_prices.columns:\n",
    "    df_prices = df_prices.withColumnRenamed(\"Volume_(Currency)\", \"volume_currency\")\n",
    "\n",
    "if \"Weighted_Price\" in df_prices.columns:\n",
    "    df_prices = df_prices.withColumnRenamed(\"Weighted_Price\", \"weighted_price\")\n",
    "\n",
    "\n",
    "# Convert Unix timestamp to a proper timestamp type\n",
    "df_prices = df_prices.withColumn(\"timestamp_utc\", from_unixtime(col(\"unix_timestamp\")).cast(\"timestamp\"))\n",
    "\n",
    "print(\"\\n Cleaned Price Data Schema and Sample :\")\n",
    "df_prices.printSchema()\n",
    "df_prices.select(\"timestamp_utc\", \"price_open\", \"price_close\", \"volume_btc\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701de7d1",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d55a14-24fa-4371-9203-3a3190721f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window, sum, count, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46907148-a18d-46d5-a97f-0302252bccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " data schema :\n",
      "root\n",
      " |-- block_timestamp: long (nullable = true)\n",
      " |-- n_inputs: integer (nullable = true)\n",
      " |-- n_outputs: integer (nullable = true)\n",
      " |-- total_amount_satoshi: long (nullable = true)\n",
      " |-- total_amount_btc: double (nullable = true)\n",
      " |-- timestamp_utc: timestamp (nullable = true)\n",
      "\n",
      "+---------------+--------+---------+--------------------+----------------+-------------------+\n",
      "|block_timestamp|n_inputs|n_outputs|total_amount_satoshi|total_amount_btc|      timestamp_utc|\n",
      "+---------------+--------+---------+--------------------+----------------+-------------------+\n",
      "|     1339713349|       1|        1|          5025512500|       50.255125|2012-06-15 00:35:49|\n",
      "|     1339713349|       4|        2|          9779326418|     97.79326418|2012-06-15 00:35:49|\n",
      "|     1339713349|       3|        2|         14502850000|        145.0285|2012-06-15 00:35:49|\n",
      "|     1339713349|       1|        1|           100000000|             1.0|2012-06-15 00:35:49|\n",
      "|     1339713349|       2|        2|          1009429329|     10.09429329|2012-06-15 00:35:49|\n",
      "+---------------+--------+---------+--------------------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "--- On-Chain Features Schema and Sample ---\n",
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- tx_count: long (nullable = false)\n",
      " |-- tx_volume_btc: double (nullable = true)\n",
      " |-- avg_inputs: double (nullable = true)\n",
      " |-- avg_outputs: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>       (7 + 1) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+--------+------------------+------------------+------------------+\n",
      "|window                                    |tx_count|tx_volume_btc     |avg_inputs        |avg_outputs       |\n",
      "+------------------------------------------+--------+------------------+------------------+------------------+\n",
      "|{2012-06-10 00:54:00, 2012-06-10 00:55:00}|87      |750.3537802699998 |2.4597701149425286|1.9540229885057472|\n",
      "|{2012-06-10 01:54:00, 2012-06-10 01:55:00}|132     |1869.5332449499995|1.7954545454545454|1.946969696969697 |\n",
      "|{2012-06-10 03:25:00, 2012-06-10 03:26:00}|189     |977.1499989299997 |1.8783068783068784|2.5396825396825395|\n",
      "|{2012-06-10 05:14:00, 2012-06-10 05:15:00}|554     |4660.899853159999 |2.108303249097473 |3.267148014440433 |\n",
      "|{2012-06-10 06:46:00, 2012-06-10 06:47:00}|233     |1512.524592979997 |1.793991416309013 |2.3433476394849784|\n",
      "|{2012-06-10 08:18:00, 2012-06-10 08:19:00}|81      |3584.4071749400005|1.5925925925925926|1.9876543209876543|\n",
      "|{2012-06-10 10:17:00, 2012-06-10 10:18:00}|512     |10252.806667159974|1.46875           |2.10546875        |\n",
      "|{2012-06-10 11:18:00, 2012-06-10 11:19:00}|420     |12563.07004679    |3.216666666666667 |2.0761904761904764|\n",
      "|{2012-06-10 12:08:00, 2012-06-10 12:09:00}|503     |2673.2388218700025|2.0596421471172963|2.0258449304174952|\n",
      "|{2012-06-10 14:15:00, 2012-06-10 14:16:00}|6       |3416.3747347799995|3.0               |1.8333333333333333|\n",
      "+------------------------------------------+--------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# load the parquet file\n",
    "transactions_path = \"../data/processed/transactions.parquet\"\n",
    "df_transactions = spark.read.parquet(transactions_path)\n",
    "\n",
    "print(\"\\n data schema :\")\n",
    "df_transactions.printSchema()\n",
    "df_transactions.show(5)\n",
    "\n",
    "# Aggregate transaction data into 1-minute windows\n",
    "# (We group transactions by time windows to match the granularity of our price data)\n",
    "onchain_features_df = df_transactions.groupBy(\n",
    "    # 'window' creates tumbling (non-overlapping) windows of a specified duration.\n",
    "    window(col(\"timestamp_utc\"), \"1 minute\")\n",
    ").agg(\n",
    "    count(\"*\").alias(\"tx_count\"),\n",
    "    sum(\"total_amount_btc\").alias(\"tx_volume_btc\"),\n",
    "    avg(\"n_inputs\").alias(\"avg_inputs\"),\n",
    "    avg(\"n_outputs\").alias(\"avg_outputs\")\n",
    ")\n",
    "\n",
    "print(\"\\n--- On-Chain Features Schema and Sample ---\")\n",
    "onchain_features_df.printSchema()\n",
    "\n",
    "# Show the results, sorting by the window time\n",
    "onchain_features_df.sort(\"window\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e43bf7-076b-47f9-a8fd-0434fc65dbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
